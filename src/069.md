# BERDL Data Lake Stewardship System â€” Multi-agent design with human-in-the-loop curation

_Multi-agent data stewardship with human-in-the-loop curation for a governed multi-tenant scientific data lake._

## Problem Statement

[](https://gist.github.com/dauglyon/d81a96b812b3298f8d862005387b9a0c#known-hard-problems-unsolved)

### 1. AI Dependencies
- [x] Map current location â†’ new location for each file
- [x] Verified all imports working

### Run Smart Contract Tests
```bash
# VERIFY at: https://docs.convex.dev/production/environment-variables

# Start CLI
uv pip install -e ".[modal]"

# For Prime sandbox support
await createTask({
  args: { event: v.id("users"), text: v.string() },
  handler: async (ctx, args) => {
    const identity = await ctx.auth.getUserIdentity();
    const embedding = data[0].embedding;

    // Force garbage collection hint (V8)
    permissions: ['Permission'],    // OPTIONAL: Array of required permissions
    relationship_candidates: list[str]  # FK-like column name matches
```

This will:
uv sync

# Run specific agent test
â”‚Â Â  â”œâ”€â”€ style.css
4. `config/.env` - Created with test configuration
â”œâ”€â”€ chat.yaml                  # Main chat configuration
4. `config/.env` - Created with test configuration
â”‚   â”‚   â”œâ”€â”€ theme.md
curl -X PUT http://localhost:8000/agents
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ lists.hbs
const coverData = await TagLib.initialize();

// Check which implementation is active
Convex Production Deployment:
- [ ] Dev environment uses production Convex deployment
- [ ] Configure `PAYMENT_PRIVATE_KEY` in production
- [ ] AI agents process in real-time
- [ ] Check responsive design
- [ ] Accessibility features work reliably
- [ ] Tools:
  - `clusterconfig/` - Regular cluster configuration gathering (default 2h interval)
  - `gatherConfig.gatherers` - Gatherer mode configuration (All or Custom mode with enable/disable per gatherer)
  - `gatherConfig.gatherers` - Gatherer mode configuration (All, None, or Custom)
  - `operator.go` - Main `Operator` type for periodic gathering in production
- `schemas/` - JSON schemas for notifications

**Estimated Time**: [X hours]

**Priority**: ğŸ”´ Critical / ğŸŸ¡ High / ğŸŸ  Medium / ğŸŸ¢ Low

**Verdict**: AI cost is noise compared to value âœ…

---

### Installation & Setup

```typescript
Gas Used: 65000
4. Enable annotation processing
4. **Fraud Detection** - Show risk scores being calculated
Task(kind="concat", input={"expr": "5 + 3"}, expected=8)

# Security considerations  
7. **What's your job title and industry?**

6. **How would you describe your ideal 'good day'?**

## Professional Context (@Work) Questions  
archon:search_code_examples(query="PostgreSQL connection pooling Node.js", match_count=2)
```

**During Execution (Step 2):**
```
âœ… Matching â†’ âœ… Market â†’ âœ… Risk â†’ âœ… Settlement
(All gray)
```

**Task: "Search for content in files"**

```bash
7. **Error Resilience**: System handles edge cases gracefully

### The Golden Rule: Task-Driven Development with Archon

**Acceptance Criteria**:
- [ ] Tasks automatically create appropriate git branches
- [ ] Set up LangSmith tracing project
- [ ] Update settings.rst with missing settings
  - âš ï¸ Pending: Need to document once QEMU is fully working
  - Uses configurable delay between retries (from `DataReporting.ReportPullingDelay`)

#### Conditional Gathering
export const getPaginated = query({
  args: {
    email: emailValidator,
    averageBitrate: 0,
    ap2_mandate_id=submission.ap2_mandate_id,
    status TEXT NOT NULL DEFAULT 'running'
);
```

### Integration Points

[](https://gist.github.com/dauglyon/d81a96b812b3298f8d862005387b9a0c#model-gpt-4o-mini-for-mvp)

The CI workflow automatically uploads coverage reports.

### Back-Pressure: Review Budgets with Graduated Decay

[](https://gist.github.com/dauglyon/d81a96b812b3298f8d862005387b9a0c#what-gets-cut)

-   Retry with exponential backoff (3 attempts), fallback to secondary provider (Claude Haiku)
-   Missing descriptions (null/empty check)
-   Stale tables (last\_modified threshold arithmetic)
-   Reactive watchers, correlation job (not needed with one weekly agent)
-   Missing descriptions (null/empty check)
-   Missing descriptions (null/empty check)
-   Reactive watchers, correlation job (not needed with one weekly agent)
-   Orphaned policies (set difference)
-   Auto-execution of any kind (all proposals are review-only)
-   Circuit breaker: 5 consecutive failures â†’ 5 min cooldown
-   **LLM failure is never a system failure**: deterministic pipeline runs regardless, LLM-dependent proposals simply skip that cycle

___

## Buy vs. Build: Hybrid with OpenMetadata

[](https://gist.github.com/dauglyon/d81a96b812b3298f8d862005387b9a0c#1-reviewer-engagement)

4. **Historical Queries**: List all my past trades
   - Payer creates Stripe payment intent via AP2 verification

1. Make changes to all the horrible code I had to go through, which finally led me to write this guide. Be better than the authors of that code! ğŸ˜‰

## Troubleshooting

- Uses @ryoppippi/eslint-config with TypeScript support
- Delivers services after payment confirmation

---

## CRITICAL: Verify Before Coding

### When Research Yields No Results

**CRITICAL**: Never load the full CSV into memory. The dataset is 9.2GB and will cause memory issues.

